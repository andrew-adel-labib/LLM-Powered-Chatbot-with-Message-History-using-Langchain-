{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5365f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from operator import itemgetter\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, trim_messages\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1587f3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e5f3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8fe0846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000018E5FA9E8C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000018E5FA9C430>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_model = ChatGroq(model=\"Gemma2-9b-It\", groq_api_key=groq_api_key)\n",
    "gemma_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd319a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Andrew Adel! It's nice to meet you. As a Chief AI Engineer, I imagine you're doing some fascinating work. \\n\\nWhat kind of projects are you currently involved in?  \\n\\nI'm always eager to learn more about the applications of AI.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 24, 'total_tokens': 83, 'completion_time': 0.107272727, 'prompt_time': 0.001783458, 'queue_time': 0.186817591, 'total_time': 0.109056185}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--2256105e-6466-46af-9cde-35bc651fe4fc-0', usage_metadata={'input_tokens': 24, 'output_tokens': 59, 'total_tokens': 83})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_model.invoke([HumanMessage(content=\"Hi, My name is Andrew Adel and I am a Chief AI Engineer.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56552c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Andrew Adel and that you are a Chief AI Engineer.  \\n\\nIs there anything else you'd like to tell me about yourself or your work?  I'm interested in learning more! üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 110, 'total_tokens': 160, 'completion_time': 0.090909091, 'prompt_time': 0.003285848, 'queue_time': 0.187710637, 'total_time': 0.094194939}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--8d55d6e3-d4bd-448d-97b0-7f50a323dd88-0', usage_metadata={'input_tokens': 110, 'output_tokens': 50, 'total_tokens': 160})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, My name is Andrew Adel and I am a Chief AI Engineer.\"),\n",
    "        AIMessage(content=\"It's nice to meet you, Andrew Adel! That's a fascinating title.\\n\\nAs a Chief AI Engineer, what are some of the most exciting projects you're working on right now?  \\n\\nI'm always eager to learn more about the innovative work being done in the field of AI.\\n\"),\n",
    "        HumanMessage(content=\"Hey What's my name and What do I do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c55d15c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58729df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_session_history at 0x0000018E5FB91000>, history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(runnable=gemma_model, get_session_history=get_session_history)\n",
    "with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9999e3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'chat1'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_config = {\"configurable\": {\"session_id\": \"chat1\"}}\n",
    "first_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acec66a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Andrew Adel! It's nice to meet you.\\n\\nAs a Chief AI Engineer, I imagine you're working on some fascinating projects. What are you currently focusing on in the field of AI?  \\n\\nI'm always eager to learn more about the latest advancements and applications of artificial intelligence.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 24, 'total_tokens': 89, 'completion_time': 0.118181818, 'prompt_time': 0.001325279, 'queue_time': 0.188009474, 'total_time': 0.119507097}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--645ffb16-65db-4178-be16-1782c4f86cb3-0', usage_metadata={'input_tokens': 24, 'output_tokens': 65, 'total_tokens': 89})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_gemma_response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Andrew Adel and I am a Chief AI Engineer.\")],\n",
    "    config=first_config\n",
    ")\n",
    "first_gemma_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb6a970c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew Adel! It's nice to meet you.\\n\\nAs a Chief AI Engineer, I imagine you're working on some fascinating projects. What are you currently focusing on in the field of AI?  \\n\\nI'm always eager to learn more about the latest advancements and applications of artificial intelligence.\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_gemma_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12c6f150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You told me your name is Andrew Adel.  \\n\\nIs there something else I can help you with? üòä  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 103, 'total_tokens': 129, 'completion_time': 0.047272727, 'prompt_time': 0.003515457, 'queue_time': 0.675239678, 'total_time': 0.050788184}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--41c754e4-a807-4d01-a0a8-688033f64ec8-0', usage_metadata={'input_tokens': 103, 'output_tokens': 26, 'total_tokens': 129})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=first_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5cfc66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'chat2'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_config = {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "second_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b392e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As an AI, I have no memory of past conversations and do not know your name. Please tell me your name so I can address you properly.\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 15, 'total_tokens': 48, 'completion_time': 0.06, 'prompt_time': 0.001253889, 'queue_time': 0.187116372, 'total_time': 0.061253889}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--2dc20eb6-bc17-484d-b71f-bdd264406657-0', usage_metadata={'input_tokens': 15, 'output_tokens': 33, 'total_tokens': 48})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_gemma_response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=second_config\n",
    ")\n",
    "second_gemma_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40a10554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an AI, I have no memory of past conversations and do not know your name. Please tell me your name so I can address you properly.\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_gemma_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fc75a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Tareq, it's nice to meet you!\\n\\nHow can I help you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 63, 'total_tokens': 86, 'completion_time': 0.041818182, 'prompt_time': 0.002208478, 'queue_time': 0.187542364, 'total_time': 0.04402666}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--29c4d4e9-5992-48a8-b397-c1905f436b3b-0', usage_metadata={'input_tokens': 63, 'output_tokens': 23, 'total_tokens': 86})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_gemma_response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey my name is Tareq.\")],\n",
    "    config=second_config\n",
    ")\n",
    "second_gemma_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eca589b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Tareq, it's nice to meet you!\\n\\nHow can I help you today?\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_gemma_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baebb195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Tareq. üòä  \\n\\nIs there anything else I can help you with, Tareq? \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 100, 'total_tokens': 126, 'completion_time': 0.047272727, 'prompt_time': 0.002656108, 'queue_time': 0.187534639, 'total_time': 0.049928835}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--34b334a2-af9e-4f6c-a3aa-ab62f78bf5f4-0', usage_metadata={'input_tokens': 100, 'output_tokens': 26, 'total_tokens': 126})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_gemma_response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=second_config\n",
    ")\n",
    "second_gemma_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d29a29a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Tareq. üòä  \\n\\nIs there anything else I can help you with, Tareq? \\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_gemma_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6eab309f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000018E5F4CF1C0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant. Answer all the questions to the best of your ability'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all the questions to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "first_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99d9ebdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000018E5F4CF1C0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant. Answer all the questions to the best of your ability'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000018E5FA9E8C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000018E5FA9C430>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_chain = first_prompt|gemma_model\n",
    "first_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "192344cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Andrew, it's nice to meet you! How can I help you today? üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 31, 'total_tokens': 55, 'completion_time': 0.043636364, 'prompt_time': 0.001486259, 'queue_time': 0.186252026, 'total_time': 0.045122623}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--9e6539fd-528f-4d37-97e1-097c70d6669b-0', usage_metadata={'input_tokens': 31, 'output_tokens': 24, 'total_tokens': 55})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_chain.invoke({\"messages\": [HumanMessage(content=\"Hey My name is Andrew.\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fefb1d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_session_history at 0x0000018E5FB91000>, history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(runnable=first_chain, get_session_history=get_session_history)\n",
    "with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4562037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'chat3'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "third_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71ad82ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Andrew, it's nice to meet you!  What can I do for you today? üòä \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 31, 'total_tokens': 57, 'completion_time': 0.047272727, 'prompt_time': 0.001479638, 'queue_time': 0.18631228, 'total_time': 0.048752365}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--554155d0-f9b7-4117-bec6-6de27a9950da-0', usage_metadata={'input_tokens': 31, 'output_tokens': 26, 'total_tokens': 57})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_prompt_response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My name is Andrew.\")],\n",
    "    config=third_config\n",
    ")\n",
    "first_prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "faa3b376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000018E5F4CF1C0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a helpful assistant. Answer all the questions to the best of your ability in {language}'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all the questions to the best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "second_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f568dba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000018E5F4CF1C0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a helpful assistant. Answer all the questions to the best of your ability in {language}'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000018E5FA9E8C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000018E5FA9C430>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_chain = second_prompt|gemma_model\n",
    "second_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62435947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ŸÖÿ±ÿ≠ÿ®ÿßŸãÿå ÿ£ŸÜÿØÿ±Ÿà! Ÿäÿ≥ÿπÿØŸÜŸä ÿßŸÑŸÑŸÇÿßÿ° ÿ®ŸÉ.  \\n\\nŸÖÿßÿ∞ÿß ŸäŸÖŸÉŸÜŸÜŸä ÿ£ŸÜ ÿ£ŸÅÿπŸÑ ŸÑŸÉÿü üòä\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 34, 'total_tokens': 63, 'completion_time': 0.052727273, 'prompt_time': 0.001480478, 'queue_time': 0.186869709, 'total_time': 0.054207751}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7b8bf187-502e-476f-9f01-e4bd29903e0d-0', usage_metadata={'input_tokens': 34, 'output_tokens': 29, 'total_tokens': 63})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_prompt_response = second_chain.invoke({\"messages\": [HumanMessage(content=\"Hi, My name is Andrew.\")], \"language\": \"Arabic\"})\n",
    "second_prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "314ff482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ŸÖÿ±ÿ≠ÿ®ÿßŸãÿå ÿ£ŸÜÿØÿ±Ÿà! Ÿäÿ≥ÿπÿØŸÜŸä ÿßŸÑŸÑŸÇÿßÿ° ÿ®ŸÉ.  \\n\\nŸÖÿßÿ∞ÿß ŸäŸÖŸÉŸÜŸÜŸä ÿ£ŸÜ ÿ£ŸÅÿπŸÑ ŸÑŸÉÿü üòä\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_prompt_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b34e1709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  messages: RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "}), kwargs={}, config={'run_name': 'insert_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_session_history at 0x0000018E5FB91000>, input_messages_key='messages', history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable=second_chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c2f359e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'chat4'}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourth_config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "fourth_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f69a2972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ŸÖÿ±ÿ≠ÿ®ÿßŸã Ÿäÿß ÿ£ŸÜÿØÿ±Ÿàÿå ÿ£ŸÜÿß ŸÖÿ≥ÿßÿπÿØ ÿ≥ÿπŸäÿØ ŸÑÿ™ŸÇÿØŸäŸÖ ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ©.  ŸÖÿß ÿßŸÑÿ∞Ÿä ŸäŸÖŸÉŸÜŸÜŸä ÿ£ŸÜ ÿ£ŸÅÿπŸÑ ŸÑŸÉÿü   \\n(Hello Andrew, I am a happy assistant to help. What can I do for you?) \\n\\n\\nLet me know how I can assist you! üòä\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 33, 'total_tokens': 96, 'completion_time': 0.114545455, 'prompt_time': 0.001485849, 'queue_time': 0.187135898, 'total_time': 0.116031304}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--8646a87a-d5e6-4395-921d-613cc14683e4-0', usage_metadata={'input_tokens': 33, 'output_tokens': 63, 'total_tokens': 96})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_prompt_response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Hi, I am Andrew.\")], \"language\": \"Arabic\"},\n",
    "    config=fourth_config\n",
    ")\n",
    "third_prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2475e1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ŸÖÿ±ÿ≠ÿ®ÿßŸã Ÿäÿß ÿ£ŸÜÿØÿ±Ÿàÿå ÿ£ŸÜÿß ŸÖÿ≥ÿßÿπÿØ ÿ≥ÿπŸäÿØ ŸÑÿ™ŸÇÿØŸäŸÖ ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ©.  ŸÖÿß ÿßŸÑÿ∞Ÿä ŸäŸÖŸÉŸÜŸÜŸä ÿ£ŸÜ ÿ£ŸÅÿπŸÑ ŸÑŸÉÿü   \\n(Hello Andrew, I am a happy assistant to help. What can I do for you?) \\n\\n\\nLet me know how I can assist you! üòä\\n\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_prompt_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd2326eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ÿßÿ≥ŸÖŸÉ ÿ£ŸÜÿØÿ±Ÿà.  \\n\\n(Your name is Andrew.) \\n\\n\\nIs there anything else I can help you with? üòä \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 109, 'total_tokens': 140, 'completion_time': 0.056363636, 'prompt_time': 0.002810108, 'queue_time': 0.187139986, 'total_time': 0.059173744}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ce77a8d8-bcb1-4650-a28a-dc476480e38f-0', usage_metadata={'input_tokens': 109, 'output_tokens': 31, 'total_tokens': 140})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourth_prompt_response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What's my name?\")], \"language\": \"Arabic\"},\n",
    "    config=fourth_config\n",
    ")\n",
    "fourth_prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71f9d78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ÿßÿ≥ŸÖŸÉ ÿ£ŸÜÿØÿ±Ÿà.  \\n\\n(Your name is Andrew.) \\n\\n\\nIs there anything else I can help you with? üòä \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourth_prompt_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f37fac34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableLambda(...)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=80,\n",
    "    strategy=\"last\",\n",
    "    token_counter=gemma_model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "trimmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c720f439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You're a good assistant.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi! I am Andrew.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Nice!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"What's the result of 2 + 2?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The result is 4.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Thanks!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='No problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You're a good assistant.\"),\n",
    "    HumanMessage(content=\"Hi! I am Andrew.\"),\n",
    "    AIMessage(content=\"Hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream.\"),\n",
    "    AIMessage(content=\"Nice!\"),\n",
    "    HumanMessage(content=\"What's the result of 2 + 2?\"),\n",
    "    AIMessage(content=\"The result is 4.\"),\n",
    "    HumanMessage(content=\"Thanks!\"),\n",
    "    AIMessage(content=\"No problem!\"),\n",
    "    HumanMessage(content=\"Having fun?\"),\n",
    "    AIMessage(content=\"Yes!\"),\n",
    "]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5e4de46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\Data Scientists Projects\\LLM-Powered Chatbot with Message History using Langchain\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You're a good assistant.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi! I am Andrew.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Nice!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"What's the result of 2 + 2?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The result is 4.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Thanks!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='No problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cefef823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  messages: RunnableLambda(itemgetter('messages'))\n",
       "            | RunnableLambda(...)\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['language', 'messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000018E5F4CF1C0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a helpful assistant. Answer all the questions to the best of your ability in {language}'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000018E5FA9E8C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000018E5FA9C430>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
    "    | second_prompt \n",
    "    | gemma_model\n",
    ")\n",
    "third_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5aaed07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You like vanilla ice cream!  üç¶\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 136, 'total_tokens': 147, 'completion_time': 0.02, 'prompt_time': 0.003673348, 'queue_time': 0.188902317, 'total_time': 0.023673348}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--922b13f7-c3c2-44e8-ba30-1beb4bb61356-0', usage_metadata={'input_tokens': 136, 'output_tokens': 11, 'total_tokens': 147})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifth_prompt_response = third_chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What ice cream do I like?\")],\n",
    "        \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "fifth_prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11ed60d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You like vanilla ice cream!  üç¶\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifth_prompt_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0dd93e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You asked what the result of 2 + 2 is.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 137, 'total_tokens': 152, 'completion_time': 0.027272727, 'prompt_time': 0.003445978, 'queue_time': 0.187873696, 'total_time': 0.030718705}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--1e46f024-f36a-4743-8d64-c692f7c1443d-0', usage_metadata={'input_tokens': 137, 'output_tokens': 15, 'total_tokens': 152})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sixth_prompt_response = third_chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What math problem did I ask for?\")],\n",
    "        \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "sixth_prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03de2755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked what the result of 2 + 2 is.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sixth_prompt_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b75bbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  messages: RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "}), kwargs={}, config={'run_name': 'insert_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_session_history at 0x0000018E5FB91000>, input_messages_key='messages', history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable=third_chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d4eafe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'chat5'}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifth_config = {\"configurable\": {\"session_id\": \"chat5\"}}\n",
    "fifth_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65573294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You like vanilla ice cream! üòä', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 136, 'total_tokens': 145, 'completion_time': 0.016363636, 'prompt_time': 0.003750578, 'queue_time': 0.189500365, 'total_time': 0.020114214}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a0b24602-3824-4aa7-9533-a4e30705758a-0', usage_metadata={'input_tokens': 136, 'output_tokens': 9, 'total_tokens': 145})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seventh_prompt_response = with_message_history.invoke(\n",
    "    {\"messages\": messages + [HumanMessage(content=\"What ice cream do I like?\")], \"language\": \"English\"},\n",
    "    config=fifth_config\n",
    ")\n",
    "seventh_prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d78849f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You like vanilla ice cream! üòä'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seventh_prompt_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "119d1b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You asked me what 2 + 2 equals!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 125, 'total_tokens': 138, 'completion_time': 0.023636364, 'prompt_time': 0.003293647, 'queue_time': 0.187093048, 'total_time': 0.026930011}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--5596234c-f119-4184-9549-b1795a9190cf-0', usage_metadata={'input_tokens': 125, 'output_tokens': 13, 'total_tokens': 138})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eighth_prompt_response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What math problem did I ask for?\")], \"language\": \"English\"},\n",
    "    config=fifth_config\n",
    ")\n",
    "eighth_prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04d0c7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked me what 2 + 2 equals!'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eighth_prompt_response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
